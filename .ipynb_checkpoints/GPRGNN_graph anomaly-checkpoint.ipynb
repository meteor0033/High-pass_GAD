{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81bf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 其中包括激活函数, 损失函数, 池化函数 ,通过 F.xxx() 的形式，可以方便地调用 torch.nn.functional 模块中的各种函数\n",
    "import numpy\n",
    "import argparse\n",
    "import time\n",
    "from dataset_process.dataset import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score, confusion_matrix\n",
    "from model.GPRGNN_anomaly import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95601549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, edge_index, args):\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    index = list(range(len(labels)))\n",
    "    if dataset_name == 'amazon':\n",
    "        index = list(range(3305, len(labels)))\n",
    "\n",
    "    idx_train, idx_rest, y_train, y_rest = train_test_split(index, labels[index], stratify=labels[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid, idx_test, y_valid, y_test = train_test_split(idx_rest, y_rest, stratify=y_rest,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    train_mask = torch.zeros([len(labels)]).bool()\n",
    "    val_mask = torch.zeros([len(labels)]).bool()\n",
    "    test_mask = torch.zeros([len(labels)]).bool()\n",
    "\n",
    "    train_mask[idx_train] = 1\n",
    "    val_mask[idx_valid] = 1\n",
    "    test_mask[idx_test] = 1\n",
    "    print('train/dev/test samples: ', train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_f1, final_tf1, final_trec, final_tpre, final_tmf1, final_tauc = 0., 0., 0., 0., 0., 0.\n",
    "\n",
    "    weight = (1-labels[train_mask]).sum().item() / labels[train_mask].sum().item()\n",
    "    print('cross entropy weight: ', weight)\n",
    "    time_start = time.time()\n",
    "    for e in range(args.epoch):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        # 调用模型中的forward函数\n",
    "        logits = model(features,edge_index)\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask], weight=torch.tensor([1., weight]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #验证\n",
    "        model.eval()\n",
    "        probs = logits.softmax(1)\n",
    "        f1, thres = get_best_f1(labels[val_mask], probs[val_mask])\n",
    "        preds = numpy.zeros_like(labels)\n",
    "        preds[probs[:, 1] > thres] = 1\n",
    "        trec = recall_score(labels[test_mask], preds[test_mask])\n",
    "        tpre = precision_score(labels[test_mask], preds[test_mask])\n",
    "        tmf1 = f1_score(labels[test_mask], preds[test_mask], average='macro')\n",
    "        tauc = roc_auc_score(labels[test_mask], probs[test_mask][:, 1].detach().numpy())\n",
    "\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            final_trec = trec\n",
    "            final_tpre = tpre\n",
    "            final_tmf1 = tmf1\n",
    "            final_tauc = tauc\n",
    "        print('Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss, f1, best_f1))\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('time cost: ', time_end - time_start, 's')\n",
    "    print('Test: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec*100,\n",
    "                                                                     final_tpre*100, final_tmf1*100, final_tauc*100))\n",
    "    return final_tmf1, final_tauc\n",
    "\n",
    "\n",
    "# threshold adjusting for best macro f1\n",
    "def get_best_f1(labels, probs):\n",
    "    best_f1, best_thre = 0, 0\n",
    "    for thres in np.linspace(0.05, 0.95, 19):\n",
    "        #构建一个与labels同维度的数组,并初始化所有变量为零\n",
    "        preds = np.zeros_like(labels)\n",
    "        preds[probs[:,1] > thres] = 1\n",
    "        #average='binary'：计算二分类问题中的 F1 分数（默认值）。\n",
    "        #average='micro'：对所有类别的真实和预测样本进行汇总，然后计算 F1 分数。\n",
    "        #average='macro'：计算每个类别的 F1 分数，然后取平均值。\n",
    "        #average=None：返回每个类别的 F1 分数。\n",
    "        # F1_score 详细原理间“备份”\n",
    "        mf1 = f1_score(labels, preds, average='macro')\n",
    "        if mf1 > best_f1:\n",
    "            best_f1 = mf1\n",
    "            best_thre = thres\n",
    "    return best_f1, best_thre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cdf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='tfinance', train_ratio=0.4, hid_dim=64, homo=1, epoch=200, run=1, net='GPRGNN', K=10, Gamma=None, dprate=0.5, Init='PPR', dropout=0.5, ppnp='GPR_prop', alpha=0.1)\n",
      "Graph(num_nodes=39357, num_edges=42445086,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='GPRGNN_anomaly')\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"yelp\",\n",
    "                        help=\"Dataset for this model (yelp/amazon/tfinance/tsocial)\")\n",
    "parser.add_argument(\"--train_ratio\", type=float, default=0.01, help=\"Training ratio\")\n",
    "parser.add_argument(\"--hid_dim\", type=int, default=64, help=\"Hidden layer dimension\")\n",
    "parser.add_argument(\"--homo\", type=int, default=1, help=\"1 for GCN_GAD(Homo) and 0 for GCN_GAD(Hetero)\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=200, help=\"The max number of epochs\")\n",
    "parser.add_argument(\"--run\", type=int, default=1, help=\"Running times\")\n",
    "parser.add_argument('--net', type=str, choices=['JKNet', 'GPRGNN'],default='GPRGNN')\n",
    "parser.add_argument('--K', type=int, default=10)\n",
    "parser.add_argument('--Gamma', default=None)\n",
    "parser.add_argument('--dprate', type=float, default=0.5)\n",
    "parser.add_argument('--Init', type=str,\n",
    "                        choices=['SGC', 'PPR', 'NPPR', 'Random', 'WS', 'Null'],\n",
    "                        default='PPR')\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--ppnp', default='GPR_prop',\n",
    "                        choices=['PPNP', 'GPR_prop'])\n",
    "parser.add_argument('--alpha', type=float, default=0.1)\n",
    "\n",
    "\n",
    "args = parser.parse_args(args = [])\n",
    "print(args)\n",
    "dataset_name = args.dataset\n",
    "homo = args.homo\n",
    "graph = Dataset(dataset_name, homo).graph\n",
    "#edge_index = Dataset(dataset_name, homo).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b5cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dev/test samples:  15742 7792 15823\n",
      "cross entropy weight:  20.83356449375867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 499.3223, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 410.5814, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss: 330.6917, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss: 259.7615, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss: 197.8220, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss: 144.8074, val mf1: 0.4883, (best 0.4883)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss: 100.5319, val mf1: 0.4883, (best 0.4883)\n",
      "Epoch 7, loss: 64.6655, val mf1: 0.4882, (best 0.4883)\n",
      "Epoch 8, loss: 36.7399, val mf1: 0.4876, (best 0.4883)\n",
      "Epoch 9, loss: 16.3656, val mf1: 0.4809, (best 0.4883)\n",
      "Epoch 10, loss: 18.4094, val mf1: 0.1449, (best 0.4883)\n",
      "Epoch 11, loss: 28.4285, val mf1: 0.0516, (best 0.4883)\n",
      "Epoch 12, loss: 33.1033, val mf1: 0.0567, (best 0.4883)\n",
      "Epoch 13, loss: 33.3327, val mf1: 0.0713, (best 0.4883)\n",
      "Epoch 14, loss: 31.4686, val mf1: 0.1152, (best 0.4883)\n",
      "Epoch 15, loss: 29.4447, val mf1: 0.2035, (best 0.4883)\n",
      "Epoch 16, loss: 28.4043, val mf1: 0.2732, (best 0.4883)\n",
      "Epoch 17, loss: 28.3324, val mf1: 0.3250, (best 0.4883)\n",
      "Epoch 18, loss: 28.8811, val mf1: 0.3708, (best 0.4883)\n",
      "Epoch 19, loss: 29.8405, val mf1: 0.4140, (best 0.4883)\n",
      "Epoch 20, loss: 30.7874, val mf1: 0.4331, (best 0.4883)\n",
      "Epoch 21, loss: 31.2196, val mf1: 0.4432, (best 0.4883)\n",
      "Epoch 22, loss: 31.0671, val mf1: 0.4588, (best 0.4883)\n",
      "Epoch 23, loss: 30.3567, val mf1: 0.4736, (best 0.4883)\n",
      "Epoch 24, loss: 28.6632, val mf1: 0.4749, (best 0.4883)\n",
      "Epoch 25, loss: 25.9676, val mf1: 0.4769, (best 0.4883)\n",
      "Epoch 26, loss: 22.5754, val mf1: 0.4817, (best 0.4883)\n",
      "Epoch 27, loss: 19.0244, val mf1: 0.4802, (best 0.4883)\n",
      "Epoch 28, loss: 16.0440, val mf1: 0.4662, (best 0.4883)\n",
      "Epoch 29, loss: 13.3727, val mf1: 0.4434, (best 0.4883)\n",
      "Epoch 30, loss: 10.9661, val mf1: 0.4241, (best 0.4883)\n",
      "Epoch 31, loss: 8.9480, val mf1: 0.3976, (best 0.4883)\n",
      "Epoch 32, loss: 7.4959, val mf1: 0.3769, (best 0.4883)\n",
      "Epoch 33, loss: 6.6701, val mf1: 0.3551, (best 0.4883)\n",
      "Epoch 34, loss: 6.3571, val mf1: 0.3542, (best 0.4883)\n",
      "Epoch 35, loss: 6.3806, val mf1: 0.3652, (best 0.4883)\n",
      "Epoch 36, loss: 6.5232, val mf1: 0.3798, (best 0.4883)\n",
      "Epoch 37, loss: 6.5832, val mf1: 0.3900, (best 0.4883)\n",
      "Epoch 38, loss: 6.5002, val mf1: 0.4027, (best 0.4883)\n",
      "Epoch 39, loss: 6.3082, val mf1: 0.4138, (best 0.4883)\n",
      "Epoch 40, loss: 6.0818, val mf1: 0.4234, (best 0.4883)\n",
      "Epoch 41, loss: 5.8647, val mf1: 0.4288, (best 0.4883)\n",
      "Epoch 42, loss: 5.6879, val mf1: 0.4357, (best 0.4883)\n",
      "Epoch 43, loss: 5.5884, val mf1: 0.4403, (best 0.4883)\n",
      "Epoch 44, loss: 5.5715, val mf1: 0.4438, (best 0.4883)\n",
      "Epoch 45, loss: 5.6240, val mf1: 0.4465, (best 0.4883)\n",
      "Epoch 46, loss: 5.7020, val mf1: 0.4475, (best 0.4883)\n",
      "Epoch 47, loss: 5.7627, val mf1: 0.4491, (best 0.4883)\n",
      "Epoch 48, loss: 5.7682, val mf1: 0.4486, (best 0.4883)\n",
      "Epoch 49, loss: 5.6951, val mf1: 0.4476, (best 0.4883)\n",
      "Epoch 50, loss: 5.5452, val mf1: 0.4473, (best 0.4883)\n",
      "Epoch 51, loss: 5.3262, val mf1: 0.4477, (best 0.4883)\n",
      "Epoch 52, loss: 5.0564, val mf1: 0.4464, (best 0.4883)\n",
      "Epoch 53, loss: 4.7549, val mf1: 0.4492, (best 0.4883)\n",
      "Epoch 54, loss: 4.4391, val mf1: 0.4483, (best 0.4883)\n",
      "Epoch 55, loss: 4.1366, val mf1: 0.4477, (best 0.4883)\n",
      "Epoch 56, loss: 3.8762, val mf1: 0.4475, (best 0.4883)\n",
      "Epoch 57, loss: 3.6664, val mf1: 0.4483, (best 0.4883)\n",
      "Epoch 58, loss: 3.4956, val mf1: 0.4470, (best 0.4883)\n",
      "Epoch 59, loss: 3.3275, val mf1: 0.4464, (best 0.4883)\n",
      "Epoch 60, loss: 3.1343, val mf1: 0.4444, (best 0.4883)\n",
      "Epoch 61, loss: 2.9049, val mf1: 0.4439, (best 0.4883)\n",
      "Epoch 62, loss: 2.6475, val mf1: 0.4420, (best 0.4883)\n",
      "Epoch 63, loss: 2.3852, val mf1: 0.4391, (best 0.4883)\n",
      "Epoch 64, loss: 2.1406, val mf1: 0.4351, (best 0.4883)\n",
      "Epoch 65, loss: 1.9057, val mf1: 0.4296, (best 0.4883)\n",
      "Epoch 66, loss: 1.6531, val mf1: 0.4360, (best 0.4883)\n",
      "Epoch 67, loss: 1.4379, val mf1: 0.4537, (best 0.4883)\n",
      "Epoch 68, loss: 1.3259, val mf1: 0.4673, (best 0.4883)\n",
      "Epoch 69, loss: 1.2551, val mf1: 0.4799, (best 0.4883)\n",
      "Epoch 70, loss: 1.2138, val mf1: 0.4840, (best 0.4883)\n",
      "Epoch 71, loss: 1.2535, val mf1: 0.4837, (best 0.4883)\n",
      "Epoch 72, loss: 1.2394, val mf1: 0.4810, (best 0.4883)\n",
      "Epoch 73, loss: 1.1772, val mf1: 0.4757, (best 0.4883)\n",
      "Epoch 74, loss: 1.0610, val mf1: 0.4731, (best 0.4883)\n",
      "Epoch 75, loss: 0.9163, val mf1: 0.4766, (best 0.4883)\n",
      "Epoch 76, loss: 0.8700, val mf1: 0.5229, (best 0.5229)\n",
      "Epoch 77, loss: 0.8847, val mf1: 0.5478, (best 0.5478)\n",
      "Epoch 78, loss: 0.9734, val mf1: 0.5636, (best 0.5636)\n",
      "Epoch 79, loss: 1.0287, val mf1: 0.5452, (best 0.5636)\n",
      "Epoch 80, loss: 1.0784, val mf1: 0.5267, (best 0.5636)\n",
      "Epoch 81, loss: 1.0685, val mf1: 0.5323, (best 0.5636)\n",
      "Epoch 82, loss: 1.0421, val mf1: 0.5521, (best 0.5636)\n",
      "Epoch 83, loss: 0.9804, val mf1: 0.5710, (best 0.5710)\n",
      "Epoch 84, loss: 0.9250, val mf1: 0.5659, (best 0.5710)\n",
      "Epoch 85, loss: 0.8954, val mf1: 0.5545, (best 0.5710)\n",
      "Epoch 86, loss: 0.8864, val mf1: 0.5322, (best 0.5710)\n",
      "Epoch 87, loss: 0.9131, val mf1: 0.5118, (best 0.5710)\n",
      "Epoch 88, loss: 0.8957, val mf1: 0.5016, (best 0.5710)\n",
      "Epoch 89, loss: 0.8713, val mf1: 0.4997, (best 0.5710)\n",
      "Epoch 90, loss: 0.7990, val mf1: 0.5177, (best 0.5710)\n",
      "Epoch 91, loss: 0.7582, val mf1: 0.5390, (best 0.5710)\n",
      "Epoch 92, loss: 0.7133, val mf1: 0.5575, (best 0.5710)\n",
      "Epoch 93, loss: 0.7225, val mf1: 0.5610, (best 0.5710)\n",
      "Epoch 94, loss: 0.7354, val mf1: 0.5572, (best 0.5710)\n",
      "Epoch 95, loss: 0.7197, val mf1: 0.5519, (best 0.5710)\n",
      "Epoch 96, loss: 0.7172, val mf1: 0.5273, (best 0.5710)\n",
      "Epoch 97, loss: 0.6818, val mf1: 0.5292, (best 0.5710)\n",
      "Epoch 98, loss: 0.6633, val mf1: 0.4990, (best 0.5710)\n",
      "Epoch 99, loss: 0.6985, val mf1: 0.4942, (best 0.5710)\n",
      "Epoch 100, loss: 0.6715, val mf1: 0.5037, (best 0.5710)\n",
      "Epoch 101, loss: 0.7066, val mf1: 0.4970, (best 0.5710)\n",
      "Epoch 102, loss: 0.6522, val mf1: 0.5062, (best 0.5710)\n",
      "Epoch 103, loss: 0.6200, val mf1: 0.5363, (best 0.5710)\n",
      "Epoch 104, loss: 0.6401, val mf1: 0.5784, (best 0.5784)\n",
      "Epoch 105, loss: 0.6068, val mf1: 0.6227, (best 0.6227)\n",
      "Epoch 106, loss: 0.6550, val mf1: 0.5982, (best 0.6227)\n",
      "Epoch 107, loss: 0.5909, val mf1: 0.6743, (best 0.6743)\n",
      "Epoch 108, loss: 0.5842, val mf1: 0.6718, (best 0.6743)\n",
      "Epoch 109, loss: 0.5892, val mf1: 0.6644, (best 0.6743)\n",
      "Epoch 110, loss: 0.5567, val mf1: 0.6658, (best 0.6743)\n",
      "Epoch 111, loss: 0.6028, val mf1: 0.6243, (best 0.6743)\n",
      "Epoch 112, loss: 0.5622, val mf1: 0.6698, (best 0.6743)\n",
      "Epoch 113, loss: 0.5542, val mf1: 0.6900, (best 0.6900)\n",
      "Epoch 114, loss: 0.5717, val mf1: 0.6765, (best 0.6900)\n",
      "Epoch 115, loss: 0.5304, val mf1: 0.7456, (best 0.7456)\n",
      "Epoch 116, loss: 0.5450, val mf1: 0.7524, (best 0.7524)\n",
      "Epoch 117, loss: 0.5589, val mf1: 0.7178, (best 0.7524)\n",
      "Epoch 118, loss: 0.5204, val mf1: 0.7649, (best 0.7649)\n",
      "Epoch 119, loss: 0.5776, val mf1: 0.6932, (best 0.7649)\n",
      "Epoch 120, loss: 0.5038, val mf1: 0.7832, (best 0.7832)\n",
      "Epoch 121, loss: 0.5698, val mf1: 0.6890, (best 0.7832)\n",
      "Epoch 122, loss: 0.5020, val mf1: 0.7791, (best 0.7832)\n",
      "Epoch 123, loss: 0.5608, val mf1: 0.6932, (best 0.7832)\n",
      "Epoch 124, loss: 0.4967, val mf1: 0.7905, (best 0.7905)\n",
      "Epoch 125, loss: 0.5817, val mf1: 0.6965, (best 0.7905)\n",
      "Epoch 126, loss: 0.5167, val mf1: 0.7429, (best 0.7905)\n",
      "Epoch 127, loss: 0.6117, val mf1: 0.6617, (best 0.7905)\n",
      "Epoch 128, loss: 0.5729, val mf1: 0.6847, (best 0.7905)\n",
      "Epoch 129, loss: 0.5599, val mf1: 0.7142, (best 0.7905)\n",
      "Epoch 130, loss: 0.5852, val mf1: 0.7021, (best 0.7905)\n",
      "Epoch 131, loss: 0.4871, val mf1: 0.7852, (best 0.7905)\n",
      "Epoch 132, loss: 0.5208, val mf1: 0.7247, (best 0.7905)\n",
      "Epoch 133, loss: 0.4938, val mf1: 0.7610, (best 0.7905)\n",
      "Epoch 134, loss: 0.4795, val mf1: 0.7863, (best 0.7905)\n",
      "Epoch 135, loss: 0.5264, val mf1: 0.7226, (best 0.7905)\n",
      "Epoch 136, loss: 0.4741, val mf1: 0.8044, (best 0.8044)\n",
      "Epoch 137, loss: 0.5562, val mf1: 0.7140, (best 0.8044)\n",
      "Epoch 138, loss: 0.4994, val mf1: 0.7522, (best 0.8044)\n",
      "Epoch 139, loss: 0.5774, val mf1: 0.6911, (best 0.8044)\n",
      "Epoch 140, loss: 0.5560, val mf1: 0.6993, (best 0.8044)\n",
      "Epoch 141, loss: 0.5148, val mf1: 0.7369, (best 0.8044)\n",
      "Epoch 142, loss: 0.5341, val mf1: 0.7221, (best 0.8044)\n",
      "Epoch 143, loss: 0.4897, val mf1: 0.7603, (best 0.8044)\n",
      "Epoch 144, loss: 0.4929, val mf1: 0.7538, (best 0.8044)\n",
      "Epoch 145, loss: 0.5064, val mf1: 0.7415, (best 0.8044)\n",
      "Epoch 146, loss: 0.4794, val mf1: 0.7673, (best 0.8044)\n",
      "Epoch 147, loss: 0.5349, val mf1: 0.7094, (best 0.8044)\n",
      "Epoch 148, loss: 0.4971, val mf1: 0.7495, (best 0.8044)\n",
      "Epoch 149, loss: 0.5419, val mf1: 0.7206, (best 0.8044)\n",
      "Epoch 150, loss: 0.5353, val mf1: 0.7246, (best 0.8044)\n",
      "Epoch 151, loss: 0.4909, val mf1: 0.7516, (best 0.8044)\n",
      "Epoch 152, loss: 0.5023, val mf1: 0.7382, (best 0.8044)\n",
      "Epoch 153, loss: 0.4900, val mf1: 0.7518, (best 0.8044)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154, loss: 0.4802, val mf1: 0.7623, (best 0.8044)\n",
      "Epoch 155, loss: 0.5081, val mf1: 0.7312, (best 0.8044)\n",
      "Epoch 156, loss: 0.4801, val mf1: 0.7677, (best 0.8044)\n",
      "Epoch 157, loss: 0.5257, val mf1: 0.7271, (best 0.8044)\n",
      "Epoch 158, loss: 0.5035, val mf1: 0.7403, (best 0.8044)\n",
      "Epoch 159, loss: 0.5092, val mf1: 0.7280, (best 0.8044)\n",
      "Epoch 160, loss: 0.5057, val mf1: 0.7326, (best 0.8044)\n",
      "Epoch 161, loss: 0.4927, val mf1: 0.7463, (best 0.8044)\n",
      "Epoch 162, loss: 0.4918, val mf1: 0.7463, (best 0.8044)\n",
      "Epoch 163, loss: 0.4901, val mf1: 0.7475, (best 0.8044)\n",
      "Epoch 164, loss: 0.4770, val mf1: 0.7668, (best 0.8044)\n",
      "Epoch 165, loss: 0.5046, val mf1: 0.7348, (best 0.8044)\n",
      "Epoch 166, loss: 0.4831, val mf1: 0.7513, (best 0.8044)\n",
      "Epoch 167, loss: 0.5078, val mf1: 0.7273, (best 0.8044)\n",
      "Epoch 168, loss: 0.4936, val mf1: 0.7407, (best 0.8044)\n",
      "Epoch 169, loss: 0.4964, val mf1: 0.7399, (best 0.8044)\n",
      "Epoch 170, loss: 0.4927, val mf1: 0.7421, (best 0.8044)\n",
      "Epoch 171, loss: 0.4840, val mf1: 0.7503, (best 0.8044)\n",
      "Epoch 172, loss: 0.4774, val mf1: 0.7598, (best 0.8044)\n",
      "Epoch 173, loss: 0.4911, val mf1: 0.7413, (best 0.8044)\n",
      "Epoch 174, loss: 0.4761, val mf1: 0.7520, (best 0.8044)\n",
      "Epoch 175, loss: 0.4951, val mf1: 0.7337, (best 0.8044)\n",
      "Epoch 176, loss: 0.4782, val mf1: 0.7541, (best 0.8044)\n",
      "Epoch 177, loss: 0.4966, val mf1: 0.7377, (best 0.8044)\n",
      "Epoch 178, loss: 0.4862, val mf1: 0.7436, (best 0.8044)\n",
      "Epoch 179, loss: 0.4844, val mf1: 0.7449, (best 0.8044)\n",
      "Epoch 180, loss: 0.4784, val mf1: 0.7514, (best 0.8044)\n",
      "Epoch 181, loss: 0.4830, val mf1: 0.7436, (best 0.8044)\n",
      "Epoch 182, loss: 0.4733, val mf1: 0.7504, (best 0.8044)\n",
      "Epoch 183, loss: 0.4844, val mf1: 0.7424, (best 0.8044)\n",
      "Epoch 184, loss: 0.4694, val mf1: 0.7638, (best 0.8044)\n",
      "Epoch 185, loss: 0.4906, val mf1: 0.7382, (best 0.8044)\n",
      "Epoch 186, loss: 0.4771, val mf1: 0.7480, (best 0.8044)\n",
      "Epoch 187, loss: 0.4832, val mf1: 0.7424, (best 0.8044)\n",
      "Epoch 188, loss: 0.4743, val mf1: 0.7534, (best 0.8044)\n",
      "Epoch 189, loss: 0.4801, val mf1: 0.7440, (best 0.8044)\n",
      "Epoch 190, loss: 0.4720, val mf1: 0.7493, (best 0.8044)\n",
      "Epoch 191, loss: 0.4768, val mf1: 0.7480, (best 0.8044)\n",
      "Epoch 192, loss: 0.4655, val mf1: 0.7629, (best 0.8044)\n",
      "Epoch 193, loss: 0.4815, val mf1: 0.7421, (best 0.8044)\n",
      "Epoch 194, loss: 0.4687, val mf1: 0.7519, (best 0.8044)\n",
      "Epoch 195, loss: 0.4787, val mf1: 0.7432, (best 0.8044)\n",
      "Epoch 196, loss: 0.4669, val mf1: 0.7594, (best 0.8044)\n",
      "Epoch 197, loss: 0.4788, val mf1: 0.7428, (best 0.8044)\n",
      "Epoch 198, loss: 0.4696, val mf1: 0.7499, (best 0.8044)\n",
      "Epoch 199, loss: 0.4721, val mf1: 0.7505, (best 0.8044)\n",
      "time cost:  7571.392961502075 s\n",
      "Test: REC 60.28 PRE 57.65 MF1 78.46 AUC 89.60\n",
      "MF1-mean: 78.46, MF1-std: 0.00, AUC-mean: 89.60, AUC-std: 0.00\n"
     ]
    }
   ],
   "source": [
    "in_feats = graph.ndata['feature'].shape[1]\n",
    "num_classes = 2\n",
    "\n",
    "    \n",
    "if homo:\n",
    "    edges = graph.edges()\n",
    "    edge_index =edges = torch.stack((edges[0], edges[1]))\n",
    "else:#((dataset_name ==  \"yelp\") |(dataset_name ==  \"amazon\")) and hetero\n",
    "    #三类边\n",
    "    edges_upu = graph[graph.canonical_etypes[0]].edges()\n",
    "    edge_index_upu = torch.stack(edges_upu)\n",
    "    edges_usu = graph[graph.canonical_etypes[1]].edges()\n",
    "    edge_index_usu = torch.stack(edges_usu)\n",
    "    edges_uvu = graph[graph.canonical_etypes[2]].edges()\n",
    "    edge_index_uvu = torch.stack(edges_uvu)\n",
    "    \n",
    "    # 合并连个Tensor，dim=1 按列合并\n",
    "    combined_tensor = torch.cat((edge_index_upu, edge_index_usu), dim=1)\n",
    "    edge_index = torch.cat((combined_tensor, edge_index_uvu), dim=1)\n",
    "\n",
    "\n",
    "gnn_name = args.net\n",
    "if gnn_name == 'JKNet':\n",
    "    Net = GCN_JKNet\n",
    "elif gnn_name == 'GPRGNN':\n",
    "    Net = GPRGNN\n",
    "\n",
    "if args.run == 0:\n",
    "    if homo:\n",
    "        print(\"hello\")\n",
    "        model = Net(in_feats, num_classes, graph,args)\n",
    "    else:\n",
    "        model = Net_Hetero(in_feats, num_classes,args)\n",
    "        train(model, graph,edge_index, args)\n",
    "\n",
    "else:\n",
    "    final_mf1s, final_aucs = [], []\n",
    "    for tt in range(args.run):\n",
    "        if homo:\n",
    "            #in_feats 特征点维度；h_feats：隐层维度；num_classes：节点分类数（nomal，anomaly）\n",
    "            model = Net(in_feats, num_classes, graph,args)\n",
    "        else:\n",
    "            model = Net_Hetero(in_feats, num_classes, graph,args)\n",
    "        mf1, auc = train(model, graph, edge_index, args)\n",
    "        final_mf1s.append(mf1)\n",
    "        final_aucs.append(auc)\n",
    "    final_mf1s = np.array(final_mf1s)\n",
    "    final_aucs = np.array(final_aucs)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s),\n",
    "                                                                                            100 * np.std(final_mf1s),\n",
    "                                                               100 * np.mean(final_aucs), 100 * np.std(final_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794341c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
