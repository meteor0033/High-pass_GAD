{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81bf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 其中包括激活函数, 损失函数, 池化函数 ,通过 F.xxx() 的形式，可以方便地调用 torch.nn.functional 模块中的各种函数\n",
    "import numpy\n",
    "import argparse\n",
    "import time\n",
    "from dataset_process.dataset import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score, confusion_matrix\n",
    "from model.ChebConv_anomaly import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95601549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, args):\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    index = list(range(len(labels)))\n",
    "    if dataset_name == 'amazon':\n",
    "        index = list(range(3305, len(labels)))\n",
    "\n",
    "    idx_train, idx_rest, y_train, y_rest = train_test_split(index, labels[index], stratify=labels[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid, idx_test, y_valid, y_test = train_test_split(idx_rest, y_rest, stratify=y_rest,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    train_mask = torch.zeros([len(labels)]).bool()\n",
    "    val_mask = torch.zeros([len(labels)]).bool()\n",
    "    test_mask = torch.zeros([len(labels)]).bool()\n",
    "\n",
    "    train_mask[idx_train] = 1\n",
    "    val_mask[idx_valid] = 1\n",
    "    test_mask[idx_test] = 1\n",
    "    print('train/dev/test samples: ', train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_f1, final_tf1, final_trec, final_tpre, final_tmf1, final_tauc = 0., 0., 0., 0., 0., 0.\n",
    "\n",
    "    weight = (1-labels[train_mask]).sum().item() / labels[train_mask].sum().item()\n",
    "    print('cross entropy weight: ', weight)\n",
    "    time_start = time.time()\n",
    "    for e in range(args.epoch):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        # 调用模型中的forward函数\n",
    "        logits = model(features)\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask], weight=torch.tensor([1., weight]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #验证\n",
    "        model.eval()\n",
    "        probs = logits.softmax(1)\n",
    "        f1, thres = get_best_f1(labels[val_mask], probs[val_mask])\n",
    "        preds = numpy.zeros_like(labels)\n",
    "        preds[probs[:, 1] > thres] = 1\n",
    "        trec = recall_score(labels[test_mask], preds[test_mask])\n",
    "        tpre = precision_score(labels[test_mask], preds[test_mask])\n",
    "        tmf1 = f1_score(labels[test_mask], preds[test_mask], average='macro')\n",
    "        tauc = roc_auc_score(labels[test_mask], probs[test_mask][:, 1].detach().numpy())\n",
    "\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            final_trec = trec\n",
    "            final_tpre = tpre\n",
    "            final_tmf1 = tmf1\n",
    "            final_tauc = tauc\n",
    "        print('Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss, f1, best_f1))\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('time cost: ', time_end - time_start, 's')\n",
    "    print('Test: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec*100,\n",
    "                                                                     final_tpre*100, final_tmf1*100, final_tauc*100))\n",
    "    return final_tmf1, final_tauc\n",
    "\n",
    "\n",
    "# threshold adjusting for best macro f1\n",
    "def get_best_f1(labels, probs):\n",
    "    best_f1, best_thre = 0, 0\n",
    "    for thres in np.linspace(0.05, 0.95, 19):\n",
    "        #构建一个与labels同维度的数组,并初始化所有变量为零\n",
    "        preds = np.zeros_like(labels)\n",
    "        preds[probs[:,1] > thres] = 1\n",
    "        #average='binary'：计算二分类问题中的 F1 分数（默认值）。\n",
    "        #average='micro'：对所有类别的真实和预测样本进行汇总，然后计算 F1 分数。\n",
    "        #average='macro'：计算每个类别的 F1 分数，然后取平均值。\n",
    "        #average=None：返回每个类别的 F1 分数。\n",
    "        # F1_score 详细原理间“备份”\n",
    "        mf1 = f1_score(labels, preds, average='macro')\n",
    "        if mf1 > best_f1:\n",
    "            best_f1 = mf1\n",
    "            best_thre = thres\n",
    "    return best_f1, best_thre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cdf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='tsocial', train_ratio=0.4, hid_dim=64, order=2, homo=1, epoch=100, run=1, k=3)\n",
      "Graph(num_nodes=5781065, num_edges=146211016,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='ChebConvGAD')\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"tsocial\",\n",
    "                        help=\"Dataset for this model (yelp/amazon/tfinance/tsocial)\")\n",
    "parser.add_argument(\"--train_ratio\", type=float, default=0.4, help=\"Training ratio\")\n",
    "parser.add_argument(\"--hid_dim\", type=int, default=64, help=\"Hidden layer dimension\")\n",
    "# \"Order C in Beta Wavelet\"  P + q = C ：order.  Beta 分布的概率密度函数中的两个重要参数\n",
    "parser.add_argument(\"--order\", type=int, default=2, help=\"Order C in Beta Wavelet\")\n",
    "parser.add_argument(\"--homo\", type=int, default=1, help=\"1 for ChebConvGAD(Homo) and 0 for ChebConvGAD(Hetero)\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=100, help=\"The max number of epochs\")\n",
    "parser.add_argument(\"--run\", type=int, default=1, help=\"Running times\")\n",
    "parser.add_argument(\"--k\", type=int, default=3, help=\"k in ChebConv\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(args = [])\n",
    "print(args)\n",
    "dataset_name = args.dataset\n",
    "homo = args.homo\n",
    "order = args.order\n",
    "k = args.k\n",
    "h_feats = args.hid_dim\n",
    "graph = Dataset(dataset_name, homo).graph\n",
    "#edge_index = Dataset(dataset_name, homo).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f062fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cora : data.edge_index\n",
    "#tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
    "#        [ 633, 1862, 2582,  ...,  598, 1473, 2706]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b5cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dev/test samples:  2312426 1144650 2323989\n",
      "cross entropy weight:  32.17113266008722\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 0, loss: 2.2296, val mf1: 0.4815, (best 0.4815)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 1, loss: 143.3528, val mf1: 0.0293, (best 0.4815)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 2, loss: 1.3397, val mf1: 0.5519, (best 0.5519)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 3, loss: 2.3719, val mf1: 0.4930, (best 0.5519)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 4, loss: 0.9779, val mf1: 0.5760, (best 0.5760)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 5, loss: 0.7402, val mf1: 0.6080, (best 0.6080)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 6, loss: 0.6368, val mf1: 0.6587, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 7, loss: 0.7963, val mf1: 0.5205, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 8, loss: 0.6461, val mf1: 0.6065, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 9, loss: 0.6124, val mf1: 0.6218, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 10, loss: 0.6435, val mf1: 0.6186, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 11, loss: 0.6325, val mf1: 0.6260, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 12, loss: 0.5915, val mf1: 0.6340, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 13, loss: 0.5676, val mf1: 0.6331, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 14, loss: 0.5797, val mf1: 0.6399, (best 0.6587)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 15, loss: 0.5376, val mf1: 0.6783, (best 0.6783)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 16, loss: 0.5150, val mf1: 0.7052, (best 0.7052)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 17, loss: 0.5081, val mf1: 0.7160, (best 0.7160)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 18, loss: 0.4842, val mf1: 0.7350, (best 0.7350)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 19, loss: 0.4529, val mf1: 0.7671, (best 0.7671)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 20, loss: 0.4307, val mf1: 0.7818, (best 0.7818)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 21, loss: 0.3896, val mf1: 0.7857, (best 0.7857)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 22, loss: 0.3715, val mf1: 0.7910, (best 0.7910)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 23, loss: 0.3339, val mf1: 0.8228, (best 0.8228)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 24, loss: 0.3334, val mf1: 0.8433, (best 0.8433)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 25, loss: 0.3113, val mf1: 0.8483, (best 0.8483)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 26, loss: 0.2975, val mf1: 0.8582, (best 0.8582)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 27, loss: 0.3062, val mf1: 0.8688, (best 0.8688)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 28, loss: 0.2825, val mf1: 0.8682, (best 0.8688)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 29, loss: 0.2818, val mf1: 0.8648, (best 0.8688)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 30, loss: 0.2773, val mf1: 0.8798, (best 0.8798)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 31, loss: 0.2569, val mf1: 0.8805, (best 0.8805)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 32, loss: 0.2580, val mf1: 0.8810, (best 0.8810)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 33, loss: 0.2474, val mf1: 0.8954, (best 0.8954)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 34, loss: 0.2340, val mf1: 0.8957, (best 0.8957)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 35, loss: 0.2352, val mf1: 0.8882, (best 0.8957)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 36, loss: 0.2330, val mf1: 0.8985, (best 0.8985)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 37, loss: 0.2238, val mf1: 0.8964, (best 0.8985)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 38, loss: 0.2247, val mf1: 0.8923, (best 0.8985)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 39, loss: 0.2232, val mf1: 0.9082, (best 0.9082)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 40, loss: 0.2264, val mf1: 0.8968, (best 0.9082)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 41, loss: 0.2195, val mf1: 0.9100, (best 0.9100)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 42, loss: 0.2093, val mf1: 0.9077, (best 0.9100)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 43, loss: 0.2064, val mf1: 0.9131, (best 0.9131)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 44, loss: 0.2041, val mf1: 0.9208, (best 0.9208)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 45, loss: 0.2036, val mf1: 0.9113, (best 0.9208)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 46, loss: 0.1967, val mf1: 0.9226, (best 0.9226)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 47, loss: 0.1940, val mf1: 0.9244, (best 0.9244)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 48, loss: 0.1922, val mf1: 0.9223, (best 0.9244)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 49, loss: 0.1920, val mf1: 0.9268, (best 0.9268)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 50, loss: 0.1892, val mf1: 0.9213, (best 0.9268)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 51, loss: 0.1837, val mf1: 0.9304, (best 0.9304)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 52, loss: 0.1820, val mf1: 0.9315, (best 0.9315)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 53, loss: 0.1825, val mf1: 0.9266, (best 0.9315)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 54, loss: 0.1816, val mf1: 0.9339, (best 0.9339)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 55, loss: 0.1792, val mf1: 0.9283, (best 0.9339)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 56, loss: 0.1752, val mf1: 0.9345, (best 0.9345)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 57, loss: 0.1733, val mf1: 0.9324, (best 0.9345)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 58, loss: 0.1718, val mf1: 0.9321, (best 0.9345)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 59, loss: 0.1729, val mf1: 0.9363, (best 0.9363)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 60, loss: 0.1761, val mf1: 0.9284, (best 0.9363)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 61, loss: 0.1881, val mf1: 0.9385, (best 0.9385)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 62, loss: 0.2260, val mf1: 0.8870, (best 0.9385)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 63, loss: 0.2343, val mf1: 0.9407, (best 0.9407)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 64, loss: 0.1859, val mf1: 0.9190, (best 0.9407)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 65, loss: 0.1913, val mf1: 0.9158, (best 0.9407)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 66, loss: 0.1973, val mf1: 0.9411, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 67, loss: 0.1776, val mf1: 0.9397, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 68, loss: 0.1955, val mf1: 0.9080, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 69, loss: 0.1669, val mf1: 0.9326, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 70, loss: 0.1845, val mf1: 0.9403, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 71, loss: 0.1661, val mf1: 0.9356, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 72, loss: 0.1802, val mf1: 0.9232, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 73, loss: 0.1651, val mf1: 0.9369, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 74, loss: 0.1774, val mf1: 0.9390, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 75, loss: 0.1706, val mf1: 0.9282, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 76, loss: 0.1671, val mf1: 0.9302, (best 0.9411)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 77, loss: 0.1697, val mf1: 0.9417, (best 0.9417)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 78, loss: 0.1605, val mf1: 0.9400, (best 0.9417)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 79, loss: 0.1662, val mf1: 0.9320, (best 0.9417)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 80, loss: 0.1591, val mf1: 0.9367, (best 0.9417)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 81, loss: 0.1646, val mf1: 0.9429, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 82, loss: 0.1578, val mf1: 0.9382, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 83, loss: 0.1616, val mf1: 0.9335, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 84, loss: 0.1557, val mf1: 0.9401, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 85, loss: 0.1590, val mf1: 0.9428, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 86, loss: 0.1549, val mf1: 0.9378, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 87, loss: 0.1546, val mf1: 0.9371, (best 0.9429)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 88, loss: 0.1551, val mf1: 0.9430, (best 0.9430)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 89, loss: 0.1512, val mf1: 0.9405, (best 0.9430)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 90, loss: 0.1531, val mf1: 0.9384, (best 0.9430)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 91, loss: 0.1511, val mf1: 0.9437, (best 0.9437)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 92, loss: 0.1489, val mf1: 0.9432, (best 0.9437)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 93, loss: 0.1503, val mf1: 0.9405, (best 0.9437)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 94, loss: 0.1485, val mf1: 0.9448, (best 0.9448)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 95, loss: 0.1465, val mf1: 0.9428, (best 0.9448)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 96, loss: 0.1472, val mf1: 0.9415, (best 0.9448)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 97, loss: 0.1464, val mf1: 0.9454, (best 0.9454)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 98, loss: 0.1445, val mf1: 0.9433, (best 0.9454)\n",
      "ChebConvGAD_linear2_h: torch.Size([5781065, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\chebconv.py:108: DGLWarning: lambda_max is not provided, using default value of 2.  Please use dgl.laplacian_lambda_max to compute the eigenvalues.\n",
      "  dgl_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChebConvGAD_conv1_h: torch.Size([5781065, 64])\n",
      "Epoch 99, loss: 0.1441, val mf1: 0.9434, (best 0.9454)\n",
      "time cost:  47127.605192661285 s\n",
      "Test: REC 85.28 PRE 93.63 MF1 94.47 AUC 98.14\n",
      "MF1-mean: 94.47, MF1-std: 0.00, AUC-mean: 98.14, AUC-std: 0.00\n"
     ]
    }
   ],
   "source": [
    "in_feats = graph.ndata['feature'].shape[1]\n",
    "num_classes = 2\n",
    "\n",
    "if args.run == 0:\n",
    "    if homo:\n",
    "        print(\"hello\")\n",
    "        model = ChebConvGAD(in_feats, h_feats, num_classes, graph,k = k)\n",
    "    else:\n",
    "        model = ChebConvGAD_Hetero(in_feats, h_feats, num_classes,d=order,k = k)\n",
    "        train(model, graph, args)\n",
    "\n",
    "else:\n",
    "    final_mf1s, final_aucs = [], []\n",
    "    for tt in range(args.run):\n",
    "        if homo:\n",
    "            #in_feats 特征点维度；h_feats：隐层维度；num_classes：节点分类数（nomal，anomaly）\n",
    "            model = ChebConvGAD(in_feats, h_feats, num_classes, graph,k = k)\n",
    "        else:\n",
    "            model = ChebConvGAD_Hetero(in_feats, h_feats, num_classes, graph, k = k)\n",
    "        mf1, auc = train(model, graph, args)\n",
    "        final_mf1s.append(mf1)\n",
    "        final_aucs.append(auc)\n",
    "    final_mf1s = np.array(final_mf1s)\n",
    "    final_aucs = np.array(final_aucs)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s),\n",
    "                                                                                            100 * np.std(final_mf1s),\n",
    "                                                               100 * np.mean(final_aucs), 100 * np.std(final_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ea04fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98136125])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_aucs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b61665",
   "metadata": {},
   "source": [
    "##  Test\n",
    "### 1. 按种类获取边（边存放在元组中，需要将元组转化为Tensor， 需要按边的种类，分别转化，不能一次将存放在元组中的边，转化为teosor）\n",
    "### 2. ChebConv 模型需要边的输入类型为 二维Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
    "dataset = FraudAmazonDataset()\n",
    "graph = dataset[0]\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d131ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
    "graph = dgl.add_self_loop(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5451c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.local_scope()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2f7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
    "dataset = FraudYelpDataset()\n",
    "graph = dataset[0]\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c6121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for relation in graph.canonical_etypes:\n",
    "    print(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5a3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_uvu = graph[relation].edges()\n",
    "edge_index = torch.stack(edges_uvu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d9f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#三类边\n",
    "edges_upu = graph[graph.canonical_etypes[0]].edges()\n",
    "edge_index_upu = torch.stack(edges_upu)\n",
    "edges_usu = graph[graph.canonical_etypes[1]].edges()\n",
    "edge_index_usu = torch.stack(edges_usu)\n",
    "edges_uvu = graph[graph.canonical_etypes[2]].edges()\n",
    "edge_index_uvu = torch.stack(edges_uvu)\n",
    "\n",
    "\n",
    "# 合并连个Tensor，dim=1 按列合并\n",
    "combined_tensor = torch.cat((edge_index_upu, edge_index_usu), dim=1)\n",
    "edge_index = torch.cat((combined_tensor, edge_index_uvu), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"edge_index_upu.shape:\",edge_index_upu.shape)\n",
    "print(\"edge_index_usu.shape:\",edge_index_usu.shape)\n",
    "print(\"edge_index_uvu.shape:\",edge_index_uvu.shape)\n",
    "print(\"edge_index.shape:\",edge_index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ad58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = graph[graph.canonical_etypes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import FraudYelpDataset, FraudAmazonDataset\n",
    "dataset = FraudAmazonDataset()\n",
    "graph = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.canonical_etypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7849077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2452df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if homo:\n",
    "    graph = dgl.to_homogeneous(dataset[0], ndata=['feature', 'label', 'train_mask', 'val_mask', 'test_mask'])\n",
    "  \n",
    "    graph = dgl.add_self_loop(graph)\n",
    "                \n",
    "    #三类边\n",
    "    edges_upu = graph[graph.canonical_etypes[0]].edges()\n",
    "    edge_index_upu = torch.stack(edges_upu)\n",
    "    edges_usu = graph[graph.canonical_etypes[1]].edges()\n",
    "    edge_index_usu = torch.stack(edges_usu)\n",
    "    edges_uvu = graph[graph.canonical_etypes[2]].edges()\n",
    "    edge_index_uvu = torch.stack(edges_uvu)\n",
    "                \n",
    "    # 合并连个Tensor，dim=1 按列合并\n",
    "    combined_tensor = torch.cat((edge_index_upu, edge_index_usu), dim=1)\n",
    "    edge_index = torch.cat((combined_tensor, edge_index_uvu), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.canonical_etypes)\n",
    "edge_index = graph.edges()\n",
    "edge_index = torch.stack(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0da6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
