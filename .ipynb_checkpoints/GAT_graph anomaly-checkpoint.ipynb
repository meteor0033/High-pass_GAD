{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81bf56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 其中包括激活函数, 损失函数, 池化函数 ,通过 F.xxx() 的形式，可以方便地调用 torch.nn.functional 模块中的各种函数\n",
    "import numpy\n",
    "import argparse\n",
    "import time\n",
    "from dataset_process.dataset import Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score, confusion_matrix\n",
    "from model.GAT_anomaly import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95601549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, g, args):\n",
    "    features = g.ndata['feature']\n",
    "    labels = g.ndata['label']\n",
    "    index = list(range(len(labels)))\n",
    "    if dataset_name == 'amazon':\n",
    "        index = list(range(3305, len(labels)))\n",
    "\n",
    "    idx_train, idx_rest, y_train, y_rest = train_test_split(index, labels[index], stratify=labels[index],\n",
    "                                                            train_size=args.train_ratio,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    idx_valid, idx_test, y_valid, y_test = train_test_split(idx_rest, y_rest, stratify=y_rest,\n",
    "                                                            test_size=0.67,\n",
    "                                                            random_state=2, shuffle=True)\n",
    "    train_mask = torch.zeros([len(labels)]).bool()\n",
    "    val_mask = torch.zeros([len(labels)]).bool()\n",
    "    test_mask = torch.zeros([len(labels)]).bool()\n",
    "\n",
    "    train_mask[idx_train] = 1\n",
    "    val_mask[idx_valid] = 1\n",
    "    test_mask[idx_test] = 1\n",
    "    print('train/dev/test samples: ', train_mask.sum().item(), val_mask.sum().item(), test_mask.sum().item())\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_f1, final_tf1, final_trec, final_tpre, final_tmf1, final_tauc = 0., 0., 0., 0., 0., 0.\n",
    "\n",
    "    weight = (1-labels[train_mask]).sum().item() / labels[train_mask].sum().item()\n",
    "    print('cross entropy weight: ', weight)\n",
    "    time_start = time.time()\n",
    "    for e in range(args.epoch):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        # 调用模型中的forward函数\n",
    "        logits = model(features)\n",
    "        #print(\"logits:\", logits, logits.shape)\n",
    "        #print(\"logits[train_mask]:\", logits[train_mask].shape)\n",
    "        #print(\"labels[train_mask]:\", labels[train_mask].shape)\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask], weight=torch.tensor([1., weight]))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #验证\n",
    "        model.eval()\n",
    "        probs = logits.softmax(1)\n",
    "        f1, thres = get_best_f1(labels[val_mask], probs[val_mask])\n",
    "        preds = numpy.zeros_like(labels)\n",
    "        preds[probs[:, 1] > thres] = 1\n",
    "        trec = recall_score(labels[test_mask], preds[test_mask])\n",
    "        tpre = precision_score(labels[test_mask], preds[test_mask])\n",
    "        tmf1 = f1_score(labels[test_mask], preds[test_mask], average='macro')\n",
    "        tauc = roc_auc_score(labels[test_mask], probs[test_mask][:, 1].detach().numpy())\n",
    "\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            final_trec = trec\n",
    "            final_tpre = tpre\n",
    "            final_tmf1 = tmf1\n",
    "            final_tauc = tauc\n",
    "        print('Epoch {}, loss: {:.4f}, val mf1: {:.4f}, (best {:.4f})'.format(e, loss, f1, best_f1))\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('time cost: ', time_end - time_start, 's')\n",
    "    print('Test: REC {:.2f} PRE {:.2f} MF1 {:.2f} AUC {:.2f}'.format(final_trec*100,\n",
    "                                                                     final_tpre*100, final_tmf1*100, final_tauc*100))\n",
    "    return final_tmf1, final_tauc\n",
    "\n",
    "\n",
    "# threshold adjusting for best macro f1\n",
    "def get_best_f1(labels, probs):\n",
    "    best_f1, best_thre = 0, 0\n",
    "    for thres in np.linspace(0.05, 0.95, 19):\n",
    "        #构建一个与labels同维度的数组,并初始化所有变量为零\n",
    "        preds = np.zeros_like(labels)\n",
    "        preds[probs[:,1] > thres] = 1\n",
    "        #average='binary'：计算二分类问题中的 F1 分数（默认值）。\n",
    "        #average='micro'：对所有类别的真实和预测样本进行汇总，然后计算 F1 分数。\n",
    "        #average='macro'：计算每个类别的 F1 分数，然后取平均值。\n",
    "        #average=None：返回每个类别的 F1 分数。\n",
    "        # F1_score 详细原理间“备份”\n",
    "        mf1 = f1_score(labels, preds, average='macro')\n",
    "        if mf1 > best_f1:\n",
    "            best_f1 = mf1\n",
    "            best_thre = thres\n",
    "    return best_f1, best_thre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cdf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='tsocial', train_ratio=0.4, hid_dim=64, homo=1, epoch=100, run=1)\n",
      "Graph(num_nodes=5781065, num_edges=146211016,\n",
      "      ndata_schemes={'feature': Scheme(shape=(10,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='GAT_GAD')\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"tsocial\",\n",
    "                        help=\"Dataset for this model (yelp/amazon/tfinance/tsocial)\")\n",
    "parser.add_argument(\"--train_ratio\", type=float, default=0.40, help=\"Training ratio\")\n",
    "parser.add_argument(\"--hid_dim\", type=int, default=64, help=\"Hidden layer dimension\")\n",
    "parser.add_argument(\"--homo\", type=int, default=1, help=\"1 for GAT_GAD(Homo) and 0 for GAT_GAD(Hetero)\")\n",
    "parser.add_argument(\"--epoch\", type=int, default=100, help=\"The max number of epochs\")\n",
    "parser.add_argument(\"--run\", type=int, default=1, help=\"Running times\")\n",
    "\n",
    "\n",
    "args = parser.parse_args(args = [])\n",
    "print(args)\n",
    "dataset_name = args.dataset\n",
    "homo = args.homo\n",
    "h_feats = args.hid_dim\n",
    "graph = Dataset(dataset_name, homo).graph\n",
    "#edge_index = Dataset(dataset_name, homo).edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b5cc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/dev/test samples:  2312426 1144650 2323989\n",
      "cross entropy weight:  32.17113266008722\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4439857920 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     model \u001b[38;5;241m=\u001b[39m GAT_GAD_Hetero(in_feats, h_feats, num_classes, graph, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m mf1, auc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m final_mf1s\u001b[38;5;241m.\u001b[39mappend(mf1)\n\u001b[0;32m     22\u001b[0m final_aucs\u001b[38;5;241m.\u001b[39mappend(auc)\n",
      "Cell \u001b[1;32mIn[2], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, g, args)\u001b[0m\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# 调用模型中的forward函数\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#print(\"logits:\", logits, logits.shape)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#print(\"logits[train_mask]:\", logits[train_mask].shape)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#print(\"labels[train_mask]:\", labels[train_mask].shape)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits[train_mask], labels[train_mask], weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1.\u001b[39m, weight]))\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mE:\\jupyter program\\Anomaly detection\\Rethinking-Anomaly-Detection-master_图小波变换_high-pass filter\\model\\GAT_anomaly.py:29\u001b[0m, in \u001b[0;36mGAT_GAD.forward\u001b[1;34m(self, in_feat)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_feat):\n\u001b[1;32m---> 29\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGAT1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43min_feat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     reshaped_h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mview(h\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGAT2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg,reshaped_h)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\nn\\pytorch\\conv\\gatconv.py:346\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, graph, feat, edge_weight, get_attention)\u001b[0m\n\u001b[0;32m    342\u001b[0m     graph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39medata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m edge_weight\u001b[38;5;241m.\u001b[39mtile(\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_heads, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# message passing\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu_mul_e\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m rst \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mdstdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mft\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# residual\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py:5110\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[0;32m   5108\u001b[0m _, dtid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mmetagraph\u001b[38;5;241m.\u001b[39mfind_edge(etid)\n\u001b[0;32m   5109\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m etype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m[etype]\n\u001b[1;32m-> 5110\u001b[0m ndata \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_passing\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_node_func\u001b[49m\n\u001b[0;32m   5112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5114\u001b[0m     core\u001b[38;5;241m.\u001b[39mis_builtin(reduce_func)\n\u001b[0;32m   5115\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m reduce_func\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   5116\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ndata\n\u001b[0;32m   5117\u001b[0m ):\n\u001b[0;32m   5118\u001b[0m     \u001b[38;5;66;03m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[0;32m   5119\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ndata\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\core.py:388\u001b[0m, in \u001b[0;36mmessage_passing\u001b[1;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m\"\"\"Invoke message passing computation on the whole graph.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m    Results from the message passing computation.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    382\u001b[0m     is_builtin(mfunc)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_builtin(rfunc)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    386\u001b[0m ):\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;66;03m# invoke fused message passing\u001b[39;00m\n\u001b[1;32m--> 388\u001b[0m     ndata \u001b[38;5;241m=\u001b[39m \u001b[43minvoke_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# invoke message passing in two separate steps\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;66;03m# message phase\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_builtin(mfunc):\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\core.py:349\u001b[0m, in \u001b[0;36minvoke_gspmm\u001b[1;34m(graph, mfunc, rfunc, srcdata, dstdata, edata)\u001b[0m\n\u001b[0;32m    347\u001b[0m         x \u001b[38;5;241m=\u001b[39m data_dict_to_list(graph, x, mfunc, lhs_target)\n\u001b[0;32m    348\u001b[0m         y \u001b[38;5;241m=\u001b[39m data_dict_to_list(graph, y, mfunc, rhs_target)\n\u001b[1;32m--> 349\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     x \u001b[38;5;241m=\u001b[39m alldata[mfunc\u001b[38;5;241m.\u001b[39mtarget][mfunc\u001b[38;5;241m.\u001b[39min_field]\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\ops\\spmm.py:173\u001b[0m, in \u001b[0;36m_gen_spmm_func.<locals>.func\u001b[1;34m(g, x, y)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(g, x, y):\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\ops\\spmm.py:79\u001b[0m, in \u001b[0;36mgspmm\u001b[1;34m(g, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[0;32m     77\u001b[0m         lhs_data, rhs_data \u001b[38;5;241m=\u001b[39m reshape_lhs_rhs(lhs_data, rhs_data)\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# With max and min reducers infinity will be returned for zero degree nodes\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mgspmm_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrhs_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# lhs_data or rhs_data is None only in unary functions like ``copy-u`` or ``copy_e``\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     lhs_data \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     89\u001b[0m         [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m g\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39mnumber_of_ntypes()\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lhs_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m lhs_data\n\u001b[0;32m     92\u001b[0m     )\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:1032\u001b[0m, in \u001b[0;36mgspmm\u001b[1;34m(gidx, op, reduce_op, lhs_data, rhs_data)\u001b[0m\n\u001b[0;32m   1030\u001b[0m args \u001b[38;5;241m=\u001b[39m _cast_if_autocast_enabled(gidx, op, reduce_op, lhs_data, rhs_data)\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _disable_autocast_if_enabled():\n\u001b[1;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGSpMM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\sparse.py:165\u001b[0m, in \u001b[0;36mGSpMM.forward\u001b[1;34m(ctx, gidx, op, reduce_op, X, Y)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, gidx, op, reduce_op, X, Y):\n\u001b[1;32m--> 165\u001b[0m     out, (argX, argY) \u001b[38;5;241m=\u001b[39m \u001b[43m_gspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     reduce_last \u001b[38;5;241m=\u001b[39m _need_reduce_last_dim(X, Y)\n\u001b[0;32m    167\u001b[0m     X_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\_sparse_ops.py:227\u001b[0m, in \u001b[0;36m_gspmm\u001b[1;34m(gidx, op, reduce_op, u, e)\u001b[0m\n\u001b[0;32m    223\u001b[0m _, dsttype \u001b[38;5;241m=\u001b[39m gidx\u001b[38;5;241m.\u001b[39mmetagraph\u001b[38;5;241m.\u001b[39mfind_edge(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    224\u001b[0m v_shp \u001b[38;5;241m=\u001b[39m (gidx\u001b[38;5;241m.\u001b[39mnum_nodes(dsttype),) \u001b[38;5;241m+\u001b[39m infer_broadcast_shape(\n\u001b[0;32m    225\u001b[0m     op, u_shp[\u001b[38;5;241m1\u001b[39m:], e_shp[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    226\u001b[0m )\n\u001b[1;32m--> 227\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_shp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m use_cmp \u001b[38;5;241m=\u001b[39m reduce_op \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    229\u001b[0m arg_u, arg_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:287\u001b[0m, in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, ctx)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzeros\u001b[39m(shape, dtype, ctx):\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\c10\\core\\impl\\alloc_cpu.cpp:81] data. DefaultCPUAllocator: not enough memory: you tried to allocate 4439857920 bytes."
     ]
    }
   ],
   "source": [
    "in_feats = graph.ndata['feature'].shape[1]\n",
    "num_classes = 2\n",
    "\n",
    "if args.run == 0:\n",
    "    if homo:\n",
    "        print(\"hello\")\n",
    "        model = GAT_GAD(in_feats, h_feats, num_classes, graph,num_heads=3)\n",
    "    else:\n",
    "        model = GAT_GAD_Hetero(in_feats, h_feats, num_classes,num_heads=3)\n",
    "        train(model, graph, args)\n",
    "\n",
    "else:\n",
    "    final_mf1s, final_aucs = [], []\n",
    "    for tt in range(args.run):\n",
    "        if homo:\n",
    "            #in_feats 特征点维度；h_feats：隐层维度；num_classes：节点分类数（nomal，anomaly）\n",
    "            model = GAT_GAD(in_feats, h_feats, num_classes, graph,num_heads=3)\n",
    "        else:\n",
    "            model = GAT_GAD_Hetero(in_feats, h_feats, num_classes, graph, num_heads=3)\n",
    "        mf1, auc = train(model, graph, args)\n",
    "        final_mf1s.append(mf1)\n",
    "        final_aucs.append(auc)\n",
    "    final_mf1s = np.array(final_mf1s)\n",
    "    final_aucs = np.array(final_aucs)\n",
    "    # np.std :计算全局标准差\n",
    "    print('MF1-mean: {:.2f}, MF1-std: {:.2f}, AUC-mean: {:.2f}, AUC-std: {:.2f}'.format(100 * np.mean(final_mf1s),\n",
    "                                                                                            100 * np.std(final_mf1s),\n",
    "                                                               100 * np.mean(final_aucs), 100 * np.std(final_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c641410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
